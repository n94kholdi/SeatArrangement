{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrpintime/Constraints_NeuralNet/blob/main/Constraints_NeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 7  \n"
      ],
      "metadata": {
        "id": "tAZ5NDO4Msj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Drive"
      ],
      "metadata": {
        "id": "S0fFxIXcZ8r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHbJIxi9aACQ",
        "outputId": "b5c6c92c-d737-4f01-bd60-ea28386c922d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Generative AI/Excercises/SeatArrangement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWpvsakIaQEc",
        "outputId": "ad1b2101-4dc7-4b63-e88d-be7b0944720f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Generative AI/Excercises/SeatArrangement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approche 1  \n",
        "Several Conflict Matrix"
      ],
      "metadata": {
        "id": "0SLNJXfAKXKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "list_of_conflicts = []\n",
        "\n",
        "while len(list_of_conflicts) < 50:\n",
        "    pairs_list = set()\n",
        "    matrix = np.zeros((24, 24), dtype=int)\n",
        "\n",
        "    while matrix.sum() < 40:\n",
        "        num1 = np.random.choice(range(24))\n",
        "        num2 = np.random.choice(range(24))\n",
        "\n",
        "        if num1 == num2:\n",
        "            continue\n",
        "\n",
        "        pair = (num1, num2)\n",
        "        if pair in pairs_list:\n",
        "            continue\n",
        "\n",
        "        pairs_list.add(pair)\n",
        "        matrix[num1, num2] = 1\n",
        "\n",
        "    if not any(np.array_equal(matrix, conflict) for conflict in list_of_conflicts):\n",
        "        list_of_conflicts.append(matrix)"
      ],
      "metadata": {
        "id": "lLe8nwxLJzIt"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conflicts = np.array(list_of_conflicts)"
      ],
      "metadata": {
        "id": "fvYvl0ID6xVR"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conflicts.shape"
      ],
      "metadata": {
        "id": "MMMdGqWFcOSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9562a97-29ef-4c2b-dab4-b02e930b5045"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570, 24, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_adjacent_matrix(n_seats, seats_per_row, seats_per_col):\n",
        "\n",
        "    adjacent_mask = np.zeros((n_seats, n_seats))\n",
        "\n",
        "    for i in range(n_seats):\n",
        "        if i % seats_per_row != 0:\n",
        "            adjacent_mask[i, i-1] = 1\n",
        "        if i % seats_per_row != seats_per_row-1:\n",
        "            adjacent_mask[i, i+1] = 1\n",
        "        if i >= seats_per_row:\n",
        "            adjacent_mask[i, i-seats_per_row] = 1\n",
        "        if i < n_seats-seats_per_row:\n",
        "            adjacent_mask[i, i+seats_per_row] = 1\n",
        "\n",
        "    return adjacent_mask\n",
        "\n",
        "adjacent_mask = create_adjacent_matrix(24,6,4)"
      ],
      "metadata": {
        "id": "CcVuuOSDgQSe"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural network and training"
      ],
      "metadata": {
        "id": "ZkyqDVKwL5pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as op"
      ],
      "metadata": {
        "id": "URqq-PKpL68E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeatingArr(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SeatingArr, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        # self.embedding = nn.Embedding(24, 10)  # Embedding layer for 24 people\n",
        "        self.fc1 = nn.Linear(24*24, 128, dtype=torch.float64)         # First fully connected layer\n",
        "        self.fc2 = nn.Linear(128, 64, dtype=torch.float64)            # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(64, 24*24, dtype=torch.float64)          # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        # embedded = self.embedding(x)           # Embed each person\n",
        "        # x = embedded.view(-1, 240)             # Flatten into a vector\n",
        "        x = F.relu(self.fc1(x))                # Apply first fully connected layer\n",
        "        x = F.relu(self.fc2(x))                # Apply second fully connected layer\n",
        "        x = F.relu(self.fc3(x))                        # Output layer (no activation)\n",
        "        x = x.view(-1, 24, 24)                 # Reshape to 24x24 matrix\n",
        "        x = F.softmax(x, dim=2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Apq0ItmZiAKD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_conflicts = torch.tensor(conflicts, dtype=torch.float64)\n",
        "loader = torch.utils.data.DataLoader(torch_conflicts, batch_size=64, pin_memory=True)\n",
        "examples = enumerate(loader)\n",
        "batch_idx, example_data = next(examples)"
      ],
      "metadata": {
        "id": "1aeJRUSSUkWV"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_idx, example_data.shape, loader.batch_size, loader.dataset.shape, len(loader.dataset), len(loader)"
      ],
      "metadata": {
        "id": "UAq9gapWVOzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d91c7c-7eec-423b-cd0f-7a237499a37d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, torch.Size([64, 24, 24]), 64, torch.Size([570, 24, 24]), 570, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data.type()"
      ],
      "metadata": {
        "id": "AFH5gkdNY_PG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "133fabfc-d0de-4019-e24c-ecdf2a1358cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.DoubleTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjacent_mask = create_adjacent_matrix(n_seats=24, seats_per_row=6, seats_per_col=4)\n",
        "adjacent_mask_torch = torch.tensor(adjacent_mask, dtype=torch.float64)\n",
        "\n",
        "def calculate_conflict_torch(seating_arrangement, conflict_matrix):\n",
        "    ca_mul = conflict_matrix * adjacent_mask_torch\n",
        "    conflicts = torch.sum(torch.matmul(seating_arrangement.type(torch.float64), ca_mul))\n",
        "    return conflicts\n",
        "\n",
        "def custom_loss_torch(predicted_seating_arrangement, conflicts_tensor):\n",
        "    high_factor = 10\n",
        "    loss = 0\n",
        "    batch_size = predicted_seating_arrangement.shape[0]\n",
        "\n",
        "    # Ensure the predicted seating arrangement is in float64\n",
        "    predicted_seating_arrangement = predicted_seating_arrangement.type(torch.float64)\n",
        "\n",
        "    # Calculate Conflict in produced seating arrangement\n",
        "    conflict = calculate_conflict_torch(predicted_seating_arrangement, conflicts_tensor)\n",
        "    # Ensure each seat is assigned to only one person (columns should sum to 1) (Uniqueness)\n",
        "    col_sum_loss = torch.sum((torch.sum(predicted_seating_arrangement, dim=1) - 1) ** 2) * high_factor\n",
        "    # Ensure each person gets a unique seat (rows should sum to 1) (Uniqueness)\n",
        "    row_sum_loss = torch.sum((torch.sum(predicted_seating_arrangement, dim=2) - 1) ** 2) * high_factor\n",
        "\n",
        "    loss = row_sum_loss + col_sum_loss + conflict\n",
        "\n",
        "    return loss / batch_size # Normalize"
      ],
      "metadata": {
        "id": "ptem726OVXAl"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model every 10 epochs\n",
        "interval = 20\n",
        "\n",
        "def Training(epoch):\n",
        "    # train\n",
        "    net.train()\n",
        "    for batch_idx, conflict in enumerate(loader):\n",
        "        optim.zero_grad()\n",
        "        output = net(conflict)\n",
        "        loss = custom_loss_torch(output, conflict)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "    if epoch % interval == 0:\n",
        "        print('Train Epoch: {} Loss: {:.6f}'.format(epoch, loss.item()))\n",
        "        # save state of model and optimizer\n",
        "        torch.save(net.state_dict(), './model.pth')\n",
        "        torch.save(optim.state_dict(), './optimizer.pth')\n"
      ],
      "metadata": {
        "id": "mkyWdiNUUGPc"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = SeatingArr()\n",
        "optim = op.Adam(params=net.parameters(), lr=0.00001)"
      ],
      "metadata": {
        "id": "cpX7Ykn0kwpR"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 3000\n",
        "for i in range(n_epoch):\n",
        "     Training(i+1)"
      ],
      "metadata": {
        "id": "nG9lI7z3b44f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58653279-b480-4e81-b548-8d6583f9be07"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 20 Loss: 5.777636\n",
            "Train Epoch: 40 Loss: 5.774256\n",
            "Train Epoch: 60 Loss: 5.771038\n",
            "Train Epoch: 80 Loss: 5.767974\n",
            "Train Epoch: 100 Loss: 5.764996\n",
            "Train Epoch: 120 Loss: 5.762107\n",
            "Train Epoch: 140 Loss: 5.759288\n",
            "Train Epoch: 160 Loss: 5.756503\n",
            "Train Epoch: 180 Loss: 5.753747\n",
            "Train Epoch: 200 Loss: 5.751007\n",
            "Train Epoch: 220 Loss: 5.748274\n",
            "Train Epoch: 240 Loss: 5.745515\n",
            "Train Epoch: 260 Loss: 5.742765\n",
            "Train Epoch: 280 Loss: 5.740006\n",
            "Train Epoch: 300 Loss: 5.737224\n",
            "Train Epoch: 320 Loss: 5.734447\n",
            "Train Epoch: 340 Loss: 5.731685\n",
            "Train Epoch: 360 Loss: 5.728987\n",
            "Train Epoch: 380 Loss: 5.726322\n",
            "Train Epoch: 400 Loss: 5.723731\n",
            "Train Epoch: 420 Loss: 5.721234\n",
            "Train Epoch: 440 Loss: 5.718772\n",
            "Train Epoch: 460 Loss: 5.716318\n",
            "Train Epoch: 480 Loss: 5.713906\n",
            "Train Epoch: 500 Loss: 5.711464\n",
            "Train Epoch: 520 Loss: 5.709019\n",
            "Train Epoch: 540 Loss: 5.706546\n",
            "Train Epoch: 560 Loss: 5.704107\n",
            "Train Epoch: 580 Loss: 5.701725\n",
            "Train Epoch: 600 Loss: 5.699360\n",
            "Train Epoch: 620 Loss: 5.697032\n",
            "Train Epoch: 640 Loss: 5.694743\n",
            "Train Epoch: 660 Loss: 5.692513\n",
            "Train Epoch: 680 Loss: 5.690294\n",
            "Train Epoch: 700 Loss: 5.688116\n",
            "Train Epoch: 720 Loss: 5.685997\n",
            "Train Epoch: 740 Loss: 5.683919\n",
            "Train Epoch: 760 Loss: 5.681876\n",
            "Train Epoch: 780 Loss: 5.679851\n",
            "Train Epoch: 800 Loss: 5.677849\n",
            "Train Epoch: 820 Loss: 5.675869\n",
            "Train Epoch: 840 Loss: 5.673939\n",
            "Train Epoch: 860 Loss: 5.672057\n",
            "Train Epoch: 880 Loss: 5.670224\n",
            "Train Epoch: 900 Loss: 5.668439\n",
            "Train Epoch: 920 Loss: 5.666687\n",
            "Train Epoch: 940 Loss: 5.664953\n",
            "Train Epoch: 960 Loss: 5.663261\n",
            "Train Epoch: 980 Loss: 5.661619\n",
            "Train Epoch: 1000 Loss: 5.660014\n",
            "Train Epoch: 1020 Loss: 5.658453\n",
            "Train Epoch: 1040 Loss: 5.656939\n",
            "Train Epoch: 1060 Loss: 5.655483\n",
            "Train Epoch: 1080 Loss: 5.654071\n",
            "Train Epoch: 1100 Loss: 5.652710\n",
            "Train Epoch: 1120 Loss: 5.651398\n",
            "Train Epoch: 1140 Loss: 5.650148\n",
            "Train Epoch: 1160 Loss: 5.648960\n",
            "Train Epoch: 1180 Loss: 5.647826\n",
            "Train Epoch: 1200 Loss: 5.646749\n",
            "Train Epoch: 1220 Loss: 5.645730\n",
            "Train Epoch: 1240 Loss: 5.644769\n",
            "Train Epoch: 1260 Loss: 5.643853\n",
            "Train Epoch: 1280 Loss: 5.642982\n",
            "Train Epoch: 1300 Loss: 5.642157\n",
            "Train Epoch: 1320 Loss: 5.641383\n",
            "Train Epoch: 1340 Loss: 5.640651\n",
            "Train Epoch: 1360 Loss: 5.639964\n",
            "Train Epoch: 1380 Loss: 5.639317\n",
            "Train Epoch: 1400 Loss: 5.638708\n",
            "Train Epoch: 1420 Loss: 5.638139\n",
            "Train Epoch: 1440 Loss: 5.637608\n",
            "Train Epoch: 1460 Loss: 5.637112\n",
            "Train Epoch: 1480 Loss: 5.636646\n",
            "Train Epoch: 1500 Loss: 5.636211\n",
            "Train Epoch: 1520 Loss: 5.635804\n",
            "Train Epoch: 1540 Loss: 5.635421\n",
            "Train Epoch: 1560 Loss: 5.635062\n",
            "Train Epoch: 1580 Loss: 5.634726\n",
            "Train Epoch: 1600 Loss: 5.634413\n",
            "Train Epoch: 1620 Loss: 5.634123\n",
            "Train Epoch: 1640 Loss: 5.633852\n",
            "Train Epoch: 1660 Loss: 5.633601\n",
            "Train Epoch: 1680 Loss: 5.633369\n",
            "Train Epoch: 1700 Loss: 5.633156\n",
            "Train Epoch: 1720 Loss: 5.632959\n",
            "Train Epoch: 1740 Loss: 5.632778\n",
            "Train Epoch: 1760 Loss: 5.632609\n",
            "Train Epoch: 1780 Loss: 5.632454\n",
            "Train Epoch: 1800 Loss: 5.632312\n",
            "Train Epoch: 1820 Loss: 5.632179\n",
            "Train Epoch: 1840 Loss: 5.632057\n",
            "Train Epoch: 1860 Loss: 5.631944\n",
            "Train Epoch: 1880 Loss: 5.631840\n",
            "Train Epoch: 1900 Loss: 5.631744\n",
            "Train Epoch: 1920 Loss: 5.631657\n",
            "Train Epoch: 1940 Loss: 5.631577\n",
            "Train Epoch: 1960 Loss: 5.631503\n",
            "Train Epoch: 1980 Loss: 5.631434\n",
            "Train Epoch: 2000 Loss: 5.631372\n",
            "Train Epoch: 2020 Loss: 5.631315\n",
            "Train Epoch: 2040 Loss: 5.631263\n",
            "Train Epoch: 2060 Loss: 5.631215\n",
            "Train Epoch: 2080 Loss: 5.631171\n",
            "Train Epoch: 2100 Loss: 5.631132\n",
            "Train Epoch: 2120 Loss: 5.631095\n",
            "Train Epoch: 2140 Loss: 5.631062\n",
            "Train Epoch: 2160 Loss: 5.631032\n",
            "Train Epoch: 2180 Loss: 5.631005\n",
            "Train Epoch: 2200 Loss: 5.630980\n",
            "Train Epoch: 2220 Loss: 5.630957\n",
            "Train Epoch: 2240 Loss: 5.630936\n",
            "Train Epoch: 2260 Loss: 5.630917\n",
            "Train Epoch: 2280 Loss: 5.630900\n",
            "Train Epoch: 2300 Loss: 5.630885\n",
            "Train Epoch: 2320 Loss: 5.630871\n",
            "Train Epoch: 2340 Loss: 5.630858\n",
            "Train Epoch: 2360 Loss: 5.630847\n",
            "Train Epoch: 2380 Loss: 5.630837\n",
            "Train Epoch: 2400 Loss: 5.630828\n",
            "Train Epoch: 2420 Loss: 5.630819\n",
            "Train Epoch: 2440 Loss: 5.630812\n",
            "Train Epoch: 2460 Loss: 5.630805\n",
            "Train Epoch: 2480 Loss: 5.630799\n",
            "Train Epoch: 2500 Loss: 5.630794\n",
            "Train Epoch: 2520 Loss: 5.630789\n",
            "Train Epoch: 2540 Loss: 5.630785\n",
            "Train Epoch: 2560 Loss: 5.630781\n",
            "Train Epoch: 2580 Loss: 5.630778\n",
            "Train Epoch: 2600 Loss: 5.630775\n",
            "Train Epoch: 2620 Loss: 5.630772\n",
            "Train Epoch: 2640 Loss: 5.630769\n",
            "Train Epoch: 2660 Loss: 5.630767\n",
            "Train Epoch: 2680 Loss: 5.630765\n",
            "Train Epoch: 2700 Loss: 5.630763\n",
            "Train Epoch: 2720 Loss: 5.630762\n",
            "Train Epoch: 2740 Loss: 5.630761\n",
            "Train Epoch: 2760 Loss: 5.630759\n",
            "Train Epoch: 2780 Loss: 5.630758\n",
            "Train Epoch: 2800 Loss: 5.630757\n",
            "Train Epoch: 2820 Loss: 5.630756\n",
            "Train Epoch: 2840 Loss: 5.630756\n",
            "Train Epoch: 2860 Loss: 5.630755\n",
            "Train Epoch: 2880 Loss: 5.630754\n",
            "Train Epoch: 2900 Loss: 5.630754\n",
            "Train Epoch: 2920 Loss: 5.630753\n",
            "Train Epoch: 2940 Loss: 5.630753\n",
            "Train Epoch: 2960 Loss: 5.630753\n",
            "Train Epoch: 2980 Loss: 5.630752\n",
            "Train Epoch: 3000 Loss: 5.630752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = net(torch_conflicts)\n",
        "    loss = custom_loss_torch(output, torch_conflicts)\n",
        "    loss_val = loss.item()\n",
        "    model_out_readable = torch.argmax(output, dim=2)"
      ],
      "metadata": {
        "id": "nC1DPugDckZ6"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RReXyW9iegll",
        "outputId": "672cb5c7-2330-4067-e33f-6d5fb461d992"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0481, 0.0388, 0.0388, 0.0484, 0.0474, 0.0413, 0.0388, 0.0388, 0.0388,\n",
              "         0.0404, 0.0501, 0.0396, 0.0388, 0.0469, 0.0441, 0.0388, 0.0442, 0.0438,\n",
              "         0.0388, 0.0388, 0.0388, 0.0388, 0.0388, 0.0402],\n",
              "        [0.0374, 0.0374, 0.0379, 0.0374, 0.0374, 0.0414, 0.0440, 0.0536, 0.0376,\n",
              "         0.0374, 0.0401, 0.0485, 0.0374, 0.0447, 0.0430, 0.0607, 0.0374, 0.0409,\n",
              "         0.0374, 0.0449, 0.0374, 0.0461, 0.0430, 0.0374],\n",
              "        [0.0466, 0.0508, 0.0373, 0.0384, 0.0377, 0.0373, 0.0418, 0.0373, 0.0424,\n",
              "         0.0573, 0.0383, 0.0381, 0.0373, 0.0373, 0.0373, 0.0387, 0.0391, 0.0437,\n",
              "         0.0373, 0.0493, 0.0386, 0.0487, 0.0429, 0.0469],\n",
              "        [0.0434, 0.0386, 0.0496, 0.0493, 0.0386, 0.0386, 0.0395, 0.0386, 0.0386,\n",
              "         0.0443, 0.0395, 0.0432, 0.0386, 0.0386, 0.0453, 0.0441, 0.0386, 0.0447,\n",
              "         0.0386, 0.0431, 0.0496, 0.0386, 0.0386, 0.0396],\n",
              "        [0.0519, 0.0377, 0.0447, 0.0526, 0.0377, 0.0377, 0.0442, 0.0401, 0.0443,\n",
              "         0.0377, 0.0408, 0.0426, 0.0391, 0.0442, 0.0383, 0.0377, 0.0518, 0.0377,\n",
              "         0.0377, 0.0432, 0.0430, 0.0377, 0.0401, 0.0377],\n",
              "        [0.0379, 0.0478, 0.0379, 0.0416, 0.0426, 0.0398, 0.0446, 0.0379, 0.0396,\n",
              "         0.0480, 0.0379, 0.0398, 0.0379, 0.0462, 0.0379, 0.0388, 0.0427, 0.0379,\n",
              "         0.0379, 0.0482, 0.0422, 0.0490, 0.0379, 0.0484],\n",
              "        [0.0399, 0.0399, 0.0452, 0.0399, 0.0421, 0.0421, 0.0474, 0.0399, 0.0422,\n",
              "         0.0413, 0.0409, 0.0399, 0.0399, 0.0399, 0.0482, 0.0399, 0.0399, 0.0399,\n",
              "         0.0412, 0.0477, 0.0399, 0.0419, 0.0406, 0.0399],\n",
              "        [0.0418, 0.0440, 0.0383, 0.0383, 0.0510, 0.0484, 0.0394, 0.0383, 0.0383,\n",
              "         0.0383, 0.0383, 0.0385, 0.0430, 0.0390, 0.0406, 0.0534, 0.0406, 0.0383,\n",
              "         0.0383, 0.0462, 0.0434, 0.0415, 0.0445, 0.0383],\n",
              "        [0.0397, 0.0397, 0.0397, 0.0477, 0.0397, 0.0469, 0.0397, 0.0397, 0.0397,\n",
              "         0.0470, 0.0397, 0.0397, 0.0422, 0.0397, 0.0397, 0.0433, 0.0482, 0.0397,\n",
              "         0.0405, 0.0463, 0.0427, 0.0397, 0.0397, 0.0397],\n",
              "        [0.0429, 0.0488, 0.0431, 0.0478, 0.0403, 0.0381, 0.0381, 0.0413, 0.0381,\n",
              "         0.0385, 0.0381, 0.0401, 0.0392, 0.0492, 0.0381, 0.0406, 0.0439, 0.0459,\n",
              "         0.0381, 0.0471, 0.0416, 0.0401, 0.0431, 0.0381],\n",
              "        [0.0458, 0.0385, 0.0401, 0.0404, 0.0427, 0.0385, 0.0402, 0.0513, 0.0480,\n",
              "         0.0470, 0.0385, 0.0481, 0.0433, 0.0385, 0.0385, 0.0385, 0.0482, 0.0385,\n",
              "         0.0385, 0.0413, 0.0394, 0.0385, 0.0385, 0.0392],\n",
              "        [0.0394, 0.0394, 0.0394, 0.0394, 0.0411, 0.0400, 0.0470, 0.0421, 0.0394,\n",
              "         0.0429, 0.0394, 0.0394, 0.0394, 0.0470, 0.0406, 0.0394, 0.0394, 0.0419,\n",
              "         0.0394, 0.0480, 0.0438, 0.0501, 0.0394, 0.0427],\n",
              "        [0.0373, 0.0501, 0.0406, 0.0368, 0.0368, 0.0373, 0.0460, 0.0549, 0.0448,\n",
              "         0.0522, 0.0368, 0.0384, 0.0389, 0.0368, 0.0368, 0.0430, 0.0464, 0.0396,\n",
              "         0.0368, 0.0388, 0.0368, 0.0449, 0.0469, 0.0418],\n",
              "        [0.0428, 0.0395, 0.0395, 0.0523, 0.0395, 0.0395, 0.0399, 0.0395, 0.0395,\n",
              "         0.0395, 0.0398, 0.0395, 0.0433, 0.0497, 0.0416, 0.0395, 0.0395, 0.0498,\n",
              "         0.0395, 0.0421, 0.0395, 0.0397, 0.0416, 0.0437],\n",
              "        [0.0485, 0.0379, 0.0379, 0.0448, 0.0409, 0.0379, 0.0379, 0.0379, 0.0405,\n",
              "         0.0379, 0.0379, 0.0405, 0.0535, 0.0386, 0.0386, 0.0379, 0.0445, 0.0470,\n",
              "         0.0379, 0.0414, 0.0513, 0.0467, 0.0379, 0.0446],\n",
              "        [0.0399, 0.0489, 0.0385, 0.0444, 0.0385, 0.0397, 0.0385, 0.0385, 0.0385,\n",
              "         0.0431, 0.0385, 0.0385, 0.0458, 0.0385, 0.0385, 0.0487, 0.0509, 0.0424,\n",
              "         0.0385, 0.0385, 0.0517, 0.0442, 0.0385, 0.0385],\n",
              "        [0.0383, 0.0450, 0.0408, 0.0414, 0.0376, 0.0452, 0.0449, 0.0506, 0.0375,\n",
              "         0.0375, 0.0513, 0.0375, 0.0519, 0.0401, 0.0440, 0.0375, 0.0375, 0.0472,\n",
              "         0.0375, 0.0389, 0.0375, 0.0392, 0.0440, 0.0375],\n",
              "        [0.0482, 0.0387, 0.0387, 0.0389, 0.0387, 0.0387, 0.0387, 0.0471, 0.0428,\n",
              "         0.0387, 0.0479, 0.0387, 0.0387, 0.0416, 0.0387, 0.0597, 0.0456, 0.0481,\n",
              "         0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387],\n",
              "        [0.0429, 0.0585, 0.0386, 0.0402, 0.0386, 0.0386, 0.0529, 0.0416, 0.0404,\n",
              "         0.0386, 0.0420, 0.0389, 0.0386, 0.0386, 0.0387, 0.0444, 0.0393, 0.0519,\n",
              "         0.0386, 0.0432, 0.0387, 0.0386, 0.0386, 0.0386],\n",
              "        [0.0428, 0.0362, 0.0362, 0.0395, 0.0427, 0.0380, 0.0531, 0.0408, 0.0362,\n",
              "         0.0544, 0.0362, 0.0362, 0.0537, 0.0532, 0.0384, 0.0362, 0.0399, 0.0362,\n",
              "         0.0362, 0.0369, 0.0536, 0.0462, 0.0362, 0.0411],\n",
              "        [0.0441, 0.0401, 0.0401, 0.0401, 0.0420, 0.0401, 0.0401, 0.0487, 0.0433,\n",
              "         0.0401, 0.0401, 0.0433, 0.0452, 0.0401, 0.0410, 0.0401, 0.0401, 0.0401,\n",
              "         0.0401, 0.0401, 0.0440, 0.0475, 0.0401, 0.0401],\n",
              "        [0.0381, 0.0425, 0.0381, 0.0381, 0.0381, 0.0381, 0.0418, 0.0433, 0.0440,\n",
              "         0.0381, 0.0392, 0.0451, 0.0547, 0.0511, 0.0381, 0.0437, 0.0381, 0.0495,\n",
              "         0.0381, 0.0381, 0.0470, 0.0381, 0.0381, 0.0408],\n",
              "        [0.0436, 0.0450, 0.0493, 0.0392, 0.0420, 0.0393, 0.0456, 0.0416, 0.0392,\n",
              "         0.0439, 0.0409, 0.0397, 0.0392, 0.0392, 0.0446, 0.0392, 0.0411, 0.0392,\n",
              "         0.0392, 0.0392, 0.0444, 0.0392, 0.0457, 0.0407],\n",
              "        [0.0418, 0.0392, 0.0429, 0.0459, 0.0392, 0.0508, 0.0392, 0.0395, 0.0392,\n",
              "         0.0392, 0.0410, 0.0392, 0.0434, 0.0439, 0.0423, 0.0392, 0.0460, 0.0392,\n",
              "         0.0392, 0.0429, 0.0392, 0.0491, 0.0392, 0.0392]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = 0\n",
        "for i in range(24):\n",
        "  s+=output[0][4][i]\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM8xagJylPT6",
        "outputId": "be3b13c6-be4e-4324-e86c-a3d1c1a20ada"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0000, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_out_readable[0]"
      ],
      "metadata": {
        "id": "XoP1gUQLfr6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6247290d-2d58-4fd3-c26f-249ccb560de2"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 15,  9, 20,  3, 21, 14, 15, 16, 13,  7, 21,  7,  3, 12, 20, 12, 15,\n",
              "         1,  9,  7, 12,  2,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_out_readable[2].view(4,6)"
      ],
      "metadata": {
        "id": "qhAxHqF6ftTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072f5386-6bbc-4989-b683-91117f3848e3"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[17, 11,  6,  2, 22,  1],\n",
              "        [ 4,  4, 12,  3, 11, 21],\n",
              "        [ 7, 13, 18,  1, 10, 15],\n",
              "        [ 1, 13, 21, 13, 14,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def repair_output(output):\n",
        "    remain_persons = []\n",
        "    for j in range(len(output)):\n",
        "        if j not in output:\n",
        "          remain_persons.append(j)\n",
        "    if len(remain_persons) == 0:\n",
        "        return output\n",
        "    for i in range(1, len(output)-1):\n",
        "        if output[i] in output[i+1:] or output[i] in output[:i-1]:\n",
        "            output[i] = remain_persons.pop()\n",
        "\n",
        "    return output\n",
        "\n",
        "new_output = repair_output(model_out_readable[20])\n"
      ],
      "metadata": {
        "id": "KfAoXk3Adcw9"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_output.view(4,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV7g0OQo1ZOo",
        "outputId": "4cca7c74-7f6d-438d-fdb5-c6ae5ebf3158"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[16,  8, 23, 22, 19, 14],\n",
            "        [ 4, 13,  3, 12, 11, 10],\n",
            "        [ 9,  5, 18, 20,  7, 15],\n",
            "        [ 1,  0, 21, 17,  6,  2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_output = new_output.view(4,6).numpy()\n",
        "for i in range(4):\n",
        "  for j in range(5):\n",
        "    if conflicts[0][new_output[i][j]][new_output[i][j+1]] == 1:\n",
        "      print('person in row', i, 'and col', j, 'has conflict with', new_output[i][j+1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFg6jEWnz-KG",
        "outputId": "b1104874-09f9-4104-ff9f-c0598203f78d"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person in row 0 and col 3 has conflict with 19\n",
            "person in row 2 and col 4 has conflict with 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entropy Loss Function"
      ],
      "metadata": {
        "id": "z7tyzD9gmQU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conflicts[0][20][17])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHPdCzUEzUny",
        "outputId": "250af487-dd4d-4599-a3a3-08a58c954fbc"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.pop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgLTWLC9zXhT",
        "outputId": "7df83d94-51d0-4906-fd9e-f5037d0a7f99"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o6ORkgFxzYrU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}